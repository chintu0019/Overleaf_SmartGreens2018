\section{Addressing the Challenges}
In this section, we describe the potential analytics methods that aim to provide useful tools to solve the four major problems mentioned in the introduction: resource provision, problems diagnosis, understanding user satisfaction and user behaviours.

\subsection{Resource Provision}
Let us start with the usage data from the left-most branch from the diagram in Figure~\ref{fig:schema}. A typical problem on cloud-based environment is the networking capacity management, for example the Virtual Machine (VM) selections. A common problem experienced in data centers and utility clouds is lack of knowledge about the mappings of the services being run by or offered to external users to the sets of virtual machines (VMs) that implement them~\cite{Wang2011}. It can be done by exploiting analytics methods, for example by predictive analysis on the usage data from the operating systems logs on each VM, to predict the suitable configuration for the next-time running VM.   

For an in-time decision making, Wang et al. in~\cite{Wang2011} proposed a system integrating monitoring with analytics, termed Monalytics, which can capture, aggregate, and incrementally analyze data on-demand and in real-time. It was done by applying a clustering algorithm and a top-k flow analysis [26 of Wang2011] on the data gathered from the CPU usage data on each host, finding the k flows that most contribute to the traffic between any two VMs and their sizes. It eliminates any member of the ensemble with coincidental correlations in terms of CPU usage, and provides the flow data needed to better assess the cost-benefits derived from VM migration.
 
 Usage data on VM can also be exploited to predicts VM states that can be used as the inputs of the existing networking capacity management techniques. For example, in~\cite{Sun2016}, the authors proposed a method named Smart Predictive Capacity Management (SPCM) that is designed to assist cloud networking deployment in obtaining the adequate capacity by predicting VM states. It is done by applying Markov chain techniques to address the data analytics for potential states in heterogeneous cloud computing. The outcomes of this work are significant for current enterprises that implement cloud-based applications by providing a panoramic view of the networking capacity management in different application scenarios.
 

\subsection{Problem Diagnosis}
With the increasing scale and complexity of the cloud-based applications, it has become more and more difficult for system operators to understand the behaviors of applications for tasks such as system problem diagnosis. For example, system operators need to understand system behaviors to figure out why a software system is in the current status. With such an understanding, they can choose the right operations to achieve the desired goal. System behaviors include a series of actions executed by the system and the corresponding changes in the system states. Although operators usually investigate a system starting from a specific state of interest, e.g., a hang state or failure state, contextual information for reaching that state is critical for identifying why the system runs in that state. Such contextual information includes how previous actions are executed by the system, what the historical system states are before running into the state of interest, what the input data is, etc.


\subsection{Understanding User Satisfaction and Behavior}
There are two main categories of challenges to overcome in order to achieve the stated objectives. The first category is rooted from the characteristics of the data being analyzed with analytic technologies. 

Data scale. 
Typical data in software analytics is of large scale, e.g., due to the large scale of software being developed and the large size of software development teams. Some tasks require to analyze division-wide or even company-wide code bases, which are far beyond the scope of a single code base (e.g., when conducting code- clone detection [2]). Some tasks require to analyze a large quantity of (likely noisy) data samples within or beyond a single code base (e.g., when conducting runtime-trace analysis [3]). Although lack- ing data samples may not be an issue in this context of machine learning, the large scale of data poses challenges for data process- ing and analysis, including learning-algorithm design and system building. 

Data complexity. 
Typical data in software analytics is of high complexity, which is partly due to the high complexity of software being developed. For example, runtime traces from distributed systems [3] need to be correlated, while traces from multiple threads [7] need to be split. System logs [3] include unstructured textual information. There could be high dependencies across traces and noises among traces. In addition, real-world usage data produced from in-field operations offers substantial opportunities for various tasks such as debugging (e.g., those assisted by the Microsoft Error Reporting system [4]). In addition to high complexity, such data is typically distributed and often partial (e.g., collected with sampling-based techniques to reduce runtime overhead). All these characteristics pose challenges for analytic technologies such as machine learning. The second category is rooted from the characteristics of the
tasks being assisted by software analytics. Focus on ultimate tasks being assisted. 

Among tasks assisted by software analytics, some tasks are intermediate tasks and some are ultimate tasks. Usually intermediate tasks produce information toward solving ultimate tasks. For example, code-clone detection is considered as an intermediate task, which produces information towards refactoring and defect detection that are ultimate tasks.

Such focus on ultimate tasks requires the mandatory inclusion of the phase of deployment and feedback gathering in the life cycle of a software analytic project. 

Engagement of customers during the development process of a software analytic project. It is well recognized that engaging customers is a challenging task especially in the context of software engineering tools. Customers may have resistance to proposed changes (due to analytic-tool adoption) on their existing way of carrying out a task. In addition, due to tight development schedule, they may not be able to invest time on gaining understanding of the best/worst scenarios for applying an analytic tool. However, developing a software analytic project typically needs the engagement of customers in iterations of the four phases in the project life cycle, e.g., to get better understanding on the tasks and domain knowledge. Among the phases, especially the phase of deployment and feedback gathering, it is crucial for the produced analytic tools to have good usability, e.g., providing effective visualization and manipulation of analysis results.